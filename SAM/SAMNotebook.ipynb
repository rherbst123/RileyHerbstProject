{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Segmentation Pipeline using Segment Anything Model (SAM)\n",
    "This notebook provides an end-to-end pipeline for image segmentation using Meta AI's Segment Anything Model (SAM). It includes functions for loading the model, segmenting images, visualizing results, cropping and collaging segments, and monitoring system resources during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries \n",
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import GPUtil\n",
    "import threading\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resource Monitoring\n",
    "\n",
    "# Function to get resource usage\n",
    "def get_resource_usage():\n",
    "    # Get CPU usage\n",
    "    cpu_percent = psutil.cpu_percent()\n",
    "    # Get memory usage\n",
    "    memory = psutil.virtual_memory()\n",
    "    memory_percent = memory.percent\n",
    "    # Get GPU usage\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    if gpus:\n",
    "        gpu = gpus[0]\n",
    "        gpu_percent = gpu.load * 100\n",
    "        gpu_memory_used = gpu.memoryUsed\n",
    "        gpu_memory_total = gpu.memoryTotal\n",
    "        gpu_memory_percent = (gpu_memory_used / gpu_memory_total) * 100\n",
    "    else:\n",
    "        gpu_percent = 0\n",
    "        gpu_memory_percent = 0\n",
    "    return f\"CPU:{cpu_percent:.1f}%, Mem:{memory_percent:.1f}%, GPU:{gpu_percent:.1f}%, GPU Mem:{gpu_memory_percent:.1f}%\"\n",
    "\n",
    "# Resource monitor function\n",
    "def resource_monitor(pbar, stop_event, pbar_lock):\n",
    "    while not stop_event.is_set():\n",
    "        resource_usage = get_resource_usage()\n",
    "        with pbar_lock:\n",
    "            pbar.set_postfix_str(resource_usage)\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Segment Anything Model\n",
    "def initialize_sam():\n",
    "    sam_checkpoint = \"c:\\\\Users\\\\Riley\\\\Desktop\\\\sam_vit_h_4b8939.pth\"  # Update this path as needed\n",
    "    model_type = \"vit_h\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "    sam.to(device=device)\n",
    "    return SamAutomaticMaskGenerator(\n",
    "        sam,\n",
    "        points_per_side=8,  # Number of points to sample per side of the image\n",
    "        pred_iou_thresh=0.90,  # Threshold for the predicted Intersection over Union (IoU) score\n",
    "        stability_score_thresh=0.95,  # Threshold for the stability score of the mask\n",
    "        crop_n_layers=0,  # Number of layers to crop from the image\n",
    "        crop_n_points_downscale_factor=2,  # Factor to downscale the number of points when cropping\n",
    "        min_mask_region_area=5500,  # Minimum area (in pixels) for a mask region to be considered valid\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the image\n",
    "def generate_segmentation(image_path, mask_generator):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to read image {image_path}\")\n",
    "    max_dimension = 4096\n",
    "    scale = max_dimension / max(image.shape[:2])\n",
    "    if scale < 1:\n",
    "        image = cv2.resize(image, (int(image.shape[1]*scale), int(image.shape[0]*scale)))\n",
    "    masks = mask_generator.generate(image)\n",
    "    return masks, image\n",
    "\n",
    "# Visualize segmentation results and save to file\n",
    "def visualize_and_save_segmentation(image, masks, output_path):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Correct color display\n",
    "\n",
    "    for mask in masks:\n",
    "        mask_image = mask['segmentation']\n",
    "        plt.contour(mask_image, colors=\"black\")\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop and collage the largest masks\n",
    "def crop_and_collage_largest_masks(image, masks, output_base_path):\n",
    "    # Sort masks by area in descending order\n",
    "    sorted_masks = sorted(masks, key=lambda x: x['area'], reverse=True)\n",
    "\n",
    "    # Get the top 2 masks\n",
    "    top_masks = sorted_masks[:2]\n",
    "\n",
    "    cropped_images = []\n",
    "\n",
    "    for idx, mask in enumerate(top_masks):\n",
    "        # Get the bounding box\n",
    "        x, y, w, h = mask['bbox']\n",
    "        x = int(max(x, 0))\n",
    "        y = int(max(y, 0))\n",
    "        w = int(w)\n",
    "        h = int(h)\n",
    "\n",
    "        # Ensure coordinates are within image bounds\n",
    "        x_end = min(x + w, image.shape[1])\n",
    "        y_end = min(y + h, image.shape[0])\n",
    "\n",
    "        # Crop the image\n",
    "        cropped_image = image[y:y_end, x:x_end]\n",
    "        cropped_images.append(cropped_image)\n",
    "\n",
    "    if not cropped_images:\n",
    "        print(\"No masks to collage.\")\n",
    "        return\n",
    "\n",
    "    # Resize images to have the same height\n",
    "    min_height = min(img.shape[0] for img in cropped_images)\n",
    "    resized_images = []\n",
    "    for img in cropped_images:\n",
    "        aspect_ratio = img.shape[1] / img.shape[0]\n",
    "        new_width = int(aspect_ratio * min_height)\n",
    "        resized_img = cv2.resize(img, (new_width, min_height))\n",
    "        resized_images.append(resized_img)\n",
    "\n",
    "    collage = cv2.hconcat(resized_images)\n",
    "\n",
    "    # Save Segmented Portions\n",
    "    base_name, ext = os.path.splitext(output_base_path)\n",
    "    output_path = f\"{base_name}_segmented{ext}\"\n",
    "    cv2.imwrite(output_path, collage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline processing a folder of images\n",
    "def main_pipeline(input_folder, output_folder):\n",
    "    # Get list of image files in the input folder\n",
    "    image_extensions = ('.jpg', '.jpeg', '.png')\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(image_extensions)]\n",
    "    num_images = len(image_files)\n",
    "\n",
    "    if num_images == 0:\n",
    "        print(f\"No images found in {input_folder}.\")\n",
    "        return\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    pbar_lock = threading.Lock()\n",
    "    with tqdm(total=num_images, desc='Processing Images', unit='image') as pbar:\n",
    "        # Start resource monitor thread\n",
    "        stop_event = threading.Event()\n",
    "        monitor_thread = threading.Thread(target=resource_monitor, args=(pbar, stop_event, pbar_lock))\n",
    "        monitor_thread.start()\n",
    "\n",
    "        try:\n",
    "            # Initialize SAM once\n",
    "            with pbar_lock:\n",
    "                pbar.set_description('Initializing SAM')\n",
    "            mask_generator = initialize_sam()\n",
    "\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                output_path = os.path.join(output_folder, image_file)\n",
    "\n",
    "                with pbar_lock:\n",
    "                    pbar.set_description(f'Processing {image_file}')\n",
    "                    # print(f\"Processing {image_file}\")\n",
    "\n",
    "                try:\n",
    "                    masks, image = generate_segmentation(image_path, mask_generator)\n",
    "                    visualize_and_save_segmentation(image, masks, output_path)\n",
    "                    crop_and_collage_largest_masks(image, masks, output_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_file}: {e}\")\n",
    "                finally:\n",
    "                    # Clean up to free memory\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "                with pbar_lock:\n",
    "                    pbar.update(1)\n",
    "\n",
    "            # Clean up SAM model after processing\n",
    "            del mask_generator\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        finally:\n",
    "            # Stop the resource monitor thread\n",
    "            stop_event.set()\n",
    "            monitor_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riley\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\segment_anything\\build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    }
   ],
   "source": [
    "# Initialize SAM and the mask generator\n",
    "mask_generator = initialize_sam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up to free memory\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Version: 11.8\n",
      "GPU Used: NVIDIA GeForce RTX 2060 SUPER\n",
      "Current GPU Code Used: 0\n",
      "Number of GPUs installed: 1\n",
      "Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 0019_B%2010%200279821.jpg: 100%|██████████| 10/10 [04:05<00:00, 24.51s/image, CPU:19.8%, Mem:52.4%, GPU:9.0%, GPU Mem:66.8%] \n"
     ]
    }
   ],
   "source": [
    "#Optional Run with Resource Monitoring\n",
    "if __name__ == \"__main__\":\n",
    "    # Version checking\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Cuda Version:\", torch.version.cuda)\n",
    "        print(\"GPU Used:\", torch.cuda.get_device_name(0))\n",
    "        print(\"Current GPU Code Used:\", torch.cuda.current_device())\n",
    "        print(\"Number of GPUs installed:\", torch.cuda.device_count())\n",
    "    else:\n",
    "        print(\"No GPU available\")\n",
    "\n",
    "    print(\"Starting...\")\n",
    "    input_folder = \"c:\\\\Users\\\\Riley\\\\Desktop\\\\TestSet\"  # Update this path as needed\n",
    "    output_folder = \"C:\\\\Users\\\\Riley\\\\Desktop\\\\SEGTESTINGFOLER3\"  # Update this path as needed\n",
    "\n",
    "\n",
    "    #Toggle if you want to test on one image or on a folder of images\n",
    "    # image_path = \"path_to_your_image.jpg\"  # Update this path\n",
    "    # output_path = \"path_to_output_image.jpg\"\n",
    "    main_pipeline(input_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
