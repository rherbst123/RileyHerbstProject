{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2c9256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "import GPUtil\n",
    "import threading\n",
    "import time\n",
    "import os\n",
    "from torchvision.ops import boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba5bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Riley\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\cuda\\__init__.py:235: UserWarning: \n",
      "NVIDIA GeForce RTX 5070 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 sm_80 sm_86 sm_90 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 5070 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Version: 11.8\n",
      "GPU Used: NVIDIA GeForce RTX 5070 Ti\n",
      "Current GPU Code Used: 0\n",
      "Number of GPUs installed: 1\n",
      "Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing SAM:   0%|          | 0/260 [00:04<?, ?image/s, CPU:11.4%, Mem:62.4%, GPU:5.0%, GPU Mem:14.8%]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 208\u001b[0m\n\u001b[0;32m    206\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRiley\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m300ImageTess\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m300Images_4_14_25_SatBri_Completed\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Update as needed\u001b[39;00m\n\u001b[0;32m    207\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mRiley\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m300ImagesSegmentted4_15_25_FourthRun\u001b[39m\u001b[38;5;124m\"\u001b[39m               \u001b[38;5;66;03m# Update as needed\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m \u001b[43mmain_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 159\u001b[0m, in \u001b[0;36mmain_pipeline\u001b[1;34m(input_folder, output_folder)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pbar_lock:\n\u001b[0;32m    158\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitializing SAM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 159\u001b[0m mask_generator \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_sam\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_file \u001b[38;5;129;01min\u001b[39;00m image_files:\n\u001b[0;32m    162\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, image_file)\n",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m, in \u001b[0;36minitialize_sam\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvit_h\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     37\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 39\u001b[0m sam \u001b[38;5;241m=\u001b[39m \u001b[43msam_model_registry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msam_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m sam\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SamAutomaticMaskGenerator(\n\u001b[0;32m     42\u001b[0m     sam,\n\u001b[0;32m     43\u001b[0m     points_per_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19\u001b[39m,          \u001b[38;5;66;03m# Number of points per side of the image\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     min_mask_region_area\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14500\u001b[39m,  \u001b[38;5;66;03m# Minimum area for valid mask region\u001b[39;00m\n\u001b[0;32m     49\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\segment_anything\\build_sam.py:15\u001b[0m, in \u001b[0;36mbuild_sam_vit_h\u001b[1;34m(checkpoint)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_sam_vit_h\u001b[39m(checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_sam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_embed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1280\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_num_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_global_attn_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m31\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\segment_anything\\build_sam.py:105\u001b[0m, in \u001b[0;36m_build_sam\u001b[1;34m(encoder_embed_dim, encoder_depth, encoder_num_heads, encoder_global_attn_indexes, checkpoint)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(checkpoint, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 105\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     sam\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sam\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:1462\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1465\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[0;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[1;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_weights_only_unpickler.py:512\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39m_maybe_decode_ascii(pid[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m     ):\n\u001b[0;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[0;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m         )\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[38;5;241m0\u001b[39m], LONG_BINGET[\u001b[38;5;241m0\u001b[39m]]:\n\u001b[0;32m    514\u001b[0m     idx \u001b[38;5;241m=\u001b[39m (read(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m BINGET[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, read(\u001b[38;5;241m4\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\serialization.py:1888\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1885\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset : storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[0;32m   1886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1887\u001b[0m     storage \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1888\u001b[0m         \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1889\u001b[0m         \u001b[38;5;241m.\u001b[39m_typed_storage()\n\u001b[0;32m   1890\u001b[0m         \u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[0;32m   1891\u001b[0m     )\n\u001b[0;32m   1892\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[0;32m   1893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Patch for boxes.batched_nms\n",
    "_original_batched_nms = boxes.batched_nms\n",
    "def patched_batched_nms(boxes_tensor, scores, idxs, iou_threshold):\n",
    "    boxes_tensor = boxes_tensor.cpu()\n",
    "    scores = scores.cpu()\n",
    "    idxs = idxs.cpu()\n",
    "    return _original_batched_nms(boxes_tensor, scores, idxs, iou_threshold)\n",
    "boxes.batched_nms = patched_batched_nms\n",
    "\n",
    "def get_resource_usage():\n",
    "    cpu_percent = psutil.cpu_percent()\n",
    "    memory = psutil.virtual_memory()\n",
    "    memory_percent = memory.percent\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    if gpus:\n",
    "        gpu = gpus[0]\n",
    "        gpu_percent = gpu.load * 100\n",
    "        gpu_memory_used = gpu.memoryUsed\n",
    "        gpu_memory_total = gpu.memoryTotal\n",
    "        gpu_memory_percent = (gpu_memory_used / gpu_memory_total) * 100\n",
    "    else:\n",
    "        gpu_percent = 0\n",
    "        gpu_memory_percent = 0\n",
    "    return f\"CPU:{cpu_percent:.1f}%, Mem:{memory_percent:.1f}%, GPU:{gpu_percent:.1f}%, GPU Mem:{gpu_memory_percent:.1f}%\"\n",
    "\n",
    "def resource_monitor(pbar, stop_event, pbar_lock):\n",
    "    while not stop_event.is_set():\n",
    "        resource_usage = get_resource_usage()\n",
    "        with pbar_lock:\n",
    "            pbar.set_postfix_str(resource_usage)\n",
    "        time.sleep(1)\n",
    "\n",
    "# Initialize the Segment Anything Model\n",
    "def initialize_sam():\n",
    "    sam_checkpoint = \"C:\\\\Users\\\\riley\\\\Desktop\\\\sam_vit_h_4b8939.pth\"  \n",
    "    model_type = \"vit_h\"\n",
    "    device = \"cuda\"\n",
    "    \n",
    "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "    sam.to(device=device)\n",
    "    return SamAutomaticMaskGenerator(\n",
    "        sam,\n",
    "        points_per_side=19,          # Number of points per side of the image\n",
    "        pred_iou_thresh=0.90,        # IoU threshold for predictions\n",
    "        stability_score_thresh=0.92, # Stability threshold\n",
    "        crop_n_layers=1,             # Layers to crop\n",
    "        crop_n_points_downscale_factor=0.7, # Downscale factor for points during crop\n",
    "        min_mask_region_area=14500,  # Minimum area for valid mask region\n",
    "    )\n",
    "\n",
    "# Generate segmentation masks and resized image if necessary\n",
    "def generate_segmentation(image_path, mask_generator):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Failed to read image {image_path}\")\n",
    "    max_dimension = 2250\n",
    "    scale = max_dimension / max(image.shape[:2])\n",
    "    if scale < 1:\n",
    "        image = cv2.resize(image, (int(image.shape[1]*scale), int(image.shape[0]*scale)))\n",
    "    masks = mask_generator.generate(image)\n",
    "    \n",
    "    # Filter out masks that are overly large compared to image area\n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    max_mask_area = image_area * 0.8\n",
    "    filtered_masks = [mask for mask in masks if mask['area'] < max_mask_area]\n",
    "    \n",
    "    return filtered_masks, image\n",
    "\n",
    "# Compute Intersection over Union for two masks\n",
    "def compute_mask_iou(mask1, mask2):\n",
    "    mask1_bool = mask1.astype(bool)\n",
    "    mask2_bool = mask2.astype(bool)\n",
    "    intersection = np.logical_and(mask1_bool, mask2_bool).sum()\n",
    "    union = np.logical_or(mask1_bool, mask2_bool).sum()\n",
    "    iou = intersection / (union + 1e-6)\n",
    "    return iou\n",
    "\n",
    "# Remove duplicate masks based on IoU threshold\n",
    "def remove_duplicate_masks(masks, iou_threshold=0.80):\n",
    "    unique_masks = []\n",
    "    for mask in masks:\n",
    "        duplicate = False\n",
    "        for unique in unique_masks:\n",
    "            iou = compute_mask_iou(mask['segmentation'], unique['segmentation'])\n",
    "            if iou > iou_threshold:\n",
    "                duplicate = True\n",
    "                break\n",
    "        if not duplicate:\n",
    "            unique_masks.append(mask)\n",
    "    return unique_masks\n",
    "\n",
    "# Erode the binary mask to create a separation (buffer) between segments\n",
    "def erode_mask(mask, kernel_size=3, iterations=1):\n",
    "    mask_uint8 = (mask.astype(np.uint8)) * 255\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    eroded_mask = cv2.erode(mask_uint8, kernel, iterations=iterations)\n",
    "    return (eroded_mask > 0)\n",
    "\n",
    "# Visualize segmentation results and save as an image file\n",
    "def visualize_and_save_segmentation(image, masks, output_folder):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    for mask in masks:\n",
    "        mask_image = mask['segmentation']\n",
    "        plt.contour(mask_image, colors=\"red\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    output_file = os.path.join(output_folder, f'{os.path.basename(output_folder)}_segmentation_visualization.png')\n",
    "    plt.savefig(output_file, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "# Crop each mask from the image after applying erosion to create a separation\n",
    "def crop_and_save_masks(image, masks, output_folder, erosion_kernel_size=3, erosion_iterations=1):\n",
    "    for idx, mask in enumerate(masks):\n",
    "        # Apply erosion on the mask segmentation\n",
    "        mask_image = mask['segmentation']\n",
    "        eroded_mask = erode_mask(mask_image, kernel_size=erosion_kernel_size, iterations=erosion_iterations)\n",
    "        \n",
    "        # Get bounding box coordinates\n",
    "        x, y, w, h = mask['bbox']\n",
    "        x = int(max(x, 0))\n",
    "        y = int(max(y, 0))\n",
    "        w = int(w)\n",
    "        h = int(h)\n",
    "        x_end = min(x + w, image.shape[1])\n",
    "        y_end = min(y + h, image.shape[0])\n",
    "        \n",
    "        # Crop image and corresponding mask region\n",
    "        cropped_image = image[y:y_end, x:x_end]\n",
    "        mask_cropped = eroded_mask[y:y_end, x:x_end]\n",
    "        mask_bool = mask_cropped.astype(bool)\n",
    "        for c in range(3):  # Apply the mask to each channel\n",
    "            cropped_image[:, :, c] = cropped_image[:, :, c] * mask_bool\n",
    "\n",
    "        output_file = os.path.join(output_folder, f'mask_{idx + 1}.png')\n",
    "        cv2.imwrite(output_file, cropped_image)\n",
    "        print(f\"Segment {idx + 1}: Coordinates (x: {x}, y: {y}, width: {w}, height: {h}), File: {output_file}\")\n",
    "\n",
    "# Main pipeline for processing a folder of images\n",
    "def main_pipeline(input_folder, output_folder):\n",
    "    image_extensions = ('.jpg', '.jpeg', '.png')\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(image_extensions)]\n",
    "    num_images = len(image_files)\n",
    "    if num_images == 0:\n",
    "        print(f\"No images found in {input_folder}.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    pbar_lock = threading.Lock()\n",
    "    with tqdm(total=num_images, desc='Processing Images', unit='image') as pbar:\n",
    "        # Start resource monitor thread\n",
    "        stop_event = threading.Event()\n",
    "        monitor_thread = threading.Thread(target=resource_monitor, args=(pbar, stop_event, pbar_lock))\n",
    "        monitor_thread.start()\n",
    "\n",
    "        try:\n",
    "            with pbar_lock:\n",
    "                pbar.set_description('Initializing SAM')\n",
    "            mask_generator = initialize_sam()\n",
    "\n",
    "            for image_file in image_files:\n",
    "                image_path = os.path.join(input_folder, image_file)\n",
    "                \n",
    "                try:\n",
    "                    masks, image = generate_segmentation(image_path, mask_generator)\n",
    "                    # Remove duplicate masks based on IoU\n",
    "                    masks = remove_duplicate_masks(masks, iou_threshold=0.80)\n",
    "                    image_folder_name = os.path.splitext(image_file)[0]\n",
    "                    image_output_folder = os.path.join(output_folder, image_folder_name)\n",
    "                    os.makedirs(image_output_folder, exist_ok=True)\n",
    "\n",
    "                    with pbar_lock:\n",
    "                        pbar.set_description(f'Processing {image_file}')\n",
    "                    \n",
    "                    visualize_and_save_segmentation(image, masks, image_output_folder)\n",
    "                    crop_and_save_masks(image, masks, image_output_folder, erosion_kernel_size=3, erosion_iterations=1)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {image_file}: {e}\")\n",
    "                finally:\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "                with pbar_lock:\n",
    "                    pbar.update(1)\n",
    "\n",
    "            # Clean up the SAM model after processing\n",
    "            del mask_generator\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        finally:\n",
    "            # Stop the resource monitor thread\n",
    "            stop_event.set()\n",
    "            monitor_thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Check versions and GPU availability\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"Cuda Version:\", torch.version.cuda)\n",
    "        print(\"GPU Used:\", torch.cuda.get_device_name(0))\n",
    "        print(\"Current GPU Code Used:\", torch.cuda.current_device())\n",
    "        print(\"Number of GPUs installed:\", torch.cuda.device_count())\n",
    "    else:\n",
    "        print(\"No GPU available\")\n",
    "\n",
    "    print(\"Starting...\")\n",
    "    \n",
    "    input_folder = r\"C:\\\\Users\\\\riley\\\\Documents\\\\GitHub\\\\RileyHerbstProject\\\\DEMO\\\\Output\"  # Update as needed\n",
    "    output_folder = r\"C:\\\\Users\\\\riley\\\\Documents\\\\GitHub\\\\RileyHerbstProject\\\\DEMO\\\\Segmented_Images\"               # Update as needed\n",
    "    main_pipeline(input_folder, output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
